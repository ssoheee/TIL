# 하둡

Volume(양), Velocity(입출력 속도), Variety(다양성), Veracity(정확성), Value(가치)

대용량 데이터를 분산 처리 할 수 있는 자바 기반의 오픈소스 프레임워크

BI(BUSINESS INTELLIGNECE),  OLAP(ON-LINE ANALYTICAL PROCESSING) 시스템을 사용하는 기업은 분석을 위한 데이터를 처리하기 위해 ETL(EXTRACTION, TRANSFORMATION, LOADING) 과정을 거치게 된다.

많은 양의 데이터를 저장하기 위한 상용 RDBMS의 하드웨어를 구축하기 위해서는 비용이 상당하지만, 오픈소스의 FREE OS인 LINUX에 설치가 가능하기 때문에 비용적인 부담이 없다.

트랙잭션 처리나 무결성 보장에는 적합하지 않기 때문에 RDMBS와 함께 사용된다.

하둡이 RDBMS에 속하는 것은 아니지만 NoSQL의 핵심 기능인 데이터베이스 시스템의 역할을 수행하는 것도 아니다.





범용 컴퓨터 여러 대를 클러스터화하고, 큰 크기의 데이터를 클러스터에서 병렬로 동시에 처리하여 처리 속도를 높이는 것을 목적으로 하는 분산처리를 위한 오픈소스 프레임워크



## 구성요소

- Hadoop Common
  - 하둡의 다른 모듈을 지원하기 위한 공통 컴포넌트 모듈
- **Hadoop HDFS**
  - 분산저장을 처리하기 위한 모듈
  - 여러개의 서버를 하나의 서버처럼 묶어서 데이터를 저장
- Hadoop YARN
  - 병렬처리를 위한 클러스터 자원관리 및 스케줄링 담당
- **Hadoop Mapreduce**
  - 분산되어 저장된 데이터를 병렬 처리할 수 있게 해주는 분산 처리 모듈
  - Map 단계에서는 흩어져 있는 데이터를 key, value로 묶어준다.
  - Reduce 단계에서는 key를 중심으로 필터링 및 정렬한다.



아파치 하둡의 부사장인 아룬 머시는 하둡에서는 하둡 네트워크에 연결된 아무 기기에나 데이터를 밀어 넣는다고 표현했다. 스키마를 통해 체계적으로 정리된 RDBMS에 비교하면서 하둡의 파일 저장소를 돼지우리라고 표현할 정도이다. 하지만 정말로 하둡은 분산형 파일시스템을 통하여 대용량의 파일을 블록 구조로 우겨 넣을 뿐이다.

분산형 파일시스템은 기존의 분산처리시스템과는 다르다. 여러 대의 머신이 데이터를 처리한다는 점에서 같지만 MPI(Message Passing Interface)를 사용하는 기존의 분산처리시스템은 일부 컴퓨터가 고장나는 경우 시스템이 작동하지 않고 인터페이스가 복잡하여 프로그래밍하기 힘든 문제가 있었다. 하지만 하둡 시스템의 구성요소 중 하나인 분산파일시스템은 같은 데이터를 분산 처리하되 3개의 카피를 나누어 저장해둔다. 따라서 한 컴퓨터에서 고장이 발생하거나 느려지더라도 데이터에 접근할 수 있다.



# 하둡 에코시스템 

하둡과 관련된 프레임워크들을 하둡 에코시스템이라 한다. 하둡 코어 프로젝트(HDFS, MapReduce)와 하둡 서브 프로젝트(수집, 분석, 마이닝 등)로 구성된다. 서론에서 언급한 바와 같이 다양한 프레임워크가 존재하며, 사용자의 상황에 맞추어 조립하여 사용할 수 있다. 

## Zookeeper(주키퍼) 

하둡 에코시스템(생태계)에서 서브 프로젝트는 주로 동물들의 이름을 딴 경우가 많다. 각 동물들은 하나의 프레임워크를 구성하는데, Zookeeper(사육사)는 이름에서 그 역할을 쉽게 짐작할 수 있다. 분산 시스템 간의 정보 공유 및 상태 체크, 동기화를 처리하는 프레임워크이다. 이러한 시스템을 코디네이션 서비스 시스템이라고 한다. 분산 큐, 분산 락, 피어 그룹 대표 산출 등 다양한 기능을 가진다. 





## 빅데이터 

# 출현배경

최근에 빅데이터가 많은 관심을 받기 시작한 이유는 다음과 같습니다.

- 데이터 양의 증가와 데이터 저장기술 발달

  - SNS등장, 스마트 기기 보급으로 발생하는 데이터의 양이 증가
  - 디지털 저장기술과 장치의 발달

- 경제적 타당성 증가 / 저장장치의 가격 인하

  - 1980년대 1G 10억 이상이던 메모리 가격이 2010년대 100원 미만으로 떨어짐
  - 대용량의 데이터를 저장하여도 경제성이 있음

- 데이터 처리기술 발달

  - 분산 병렬처리 기술의 발달로 합리적인 시간 안에 데이터 분석이 가능해짐
  - CPU 발전, 클라우드 컴퓨팅, 하둡 등 오픈소스 활성화로 스케일 아웃이 편리해짐

  

  # 빅데이터 처리 단계

  빅데이터는 다음의 5단계로 처리됩니다.

  - 수집
    - 데이터를 수집하는 단계
    - 정형, 비정형, 반정형 데이터
      - 정형: DB, csv 와 같은 칼럼 단위의 형태가 존재하는 데이터
      - 반정형: xml, html 처럼 스키마가 존재하는 데이터
      - 비정형: 동영상, 음성 데이터 처럼 형태가 존재하지 않는 데이터
  - 정제
    - 수집한 데이터를 적재하기 위해 필요없는 데이터, 깨진 데이터를 정리하는 단계
      - 반정형, 비정형 데이터는 분석에 필요한 데이터 외에 필요없는 부분을 제거하는 단계가 필요함
  - 적재
    - 정제된 데이터를 분석하기 위해 적재하는 단계
    - RDB, NoSQL 데이터베이스, Redshift, Druid 등의 도구에 적재
  - 분석
    - 적재한 데이터를 의미있는 지표로 분석하는 단계
    - 의사결정권자나 이용자가 사용할 수 있는 데이터로 분석하는 단계
  - 시각화
    - 분석한 데이터를 도표로 보여주는 단계
    - 데이터를 이해하기 쉬운 차트로 분석하는 단계